---
title: "Playing with the UK economics dataset"
author: "Joao Pedro Oliveira"
date: "11/9/2018"
output: html_document
---

# My LabBook for the LPS 2018/2 Final Project. 

##This is an analysis of the "Millenium of Macroeconomic Data" dataset, gathered by the Bank of England.

First, only loading the necessary packages for this analysis. I chose to use readxl instead of the famous "xlsx" since it already comes with tidyverse, and so makes life a little easier.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(plyr)
library(readxl)
```

I'll try to awnser some questions with this data, but first let's transform the messy data (very messy data) found in the xlsx archive and transform it into tidy data that's good to analyse.
```{r}
#Downloading the file, if it doesn't already exist
file = "millenniumofdata_v3_final.xlsx"
if(!file.exists(file)){
  download.file("https://www.bankofengland.co.uk/-/media/boe/files/statistics/research-datasets/a-millennium-of-macroeconomic-data-for-the-uk.xlsx?la=en&hash=73ABBFB603A709FEEB1FD349B1C61F11527F1DE4", destfile=file)
}

#Reading the xlsx file
uk_dataxl <-  read_excel(file, sheet="A1. Headline series")

#Removing useless rows
uk_dataxl_tidy <- uk_dataxl[-c(1,2,4,5,6),]

#Making the "Description" row, the header for the Dataframe
names(uk_dataxl_tidy) <- uk_dataxl_tidy[1,]

#Removing the first row beacuse it just turned into the header
uk_dataxl_tidy <- uk_dataxl_tidy[-c(1),]

#Removing NA's. This limits the data to all the years since 1929
uk_dataxl_tidy <- na.omit(uk_dataxl_tidy)

#Removing all the columns with no headers (or that only show changes in percentages from the past year). Since these columns appear in a random way through the dataset, I removed them mannualy.
uk_dataxl_tidy <- uk_dataxl_tidy[,-c(3,5,7,9,11,13, 27, 40, 55, 62, 64, 66, 68,69, 73,75,74,77)]
uk_dataxl_tidy <- uk_dataxl_tidy[,-c(26, 38, 52, 56, 58, 61, 63, 65)]
uk_dataxl_tidy <- uk_dataxl_tidy[,-c(17)]

#Transforming all the columns on the dataframe to Numeric values, as oposed to Chr
uk_dataxl_tidy[] <- lapply(uk_dataxl_tidy, function(x) {
    as.numeric(x)
})

#Renaming columns
uk_dataxl_tidy <- rename(uk_dataxl_tidy, c("Description" = "Year", "Population (GB+NI)" = "Population"))
uk_dataxl_tidy
```

The question that I'm trying to awnser with this dataset is: Can we spot the effect of significant historical moments on the data? (Example: the Industrial Revolution, WWI, WWII, and the Great Recession)

To awnser that question, I figured we need to find and compare some indicators that might give us our awnser. For example, the Unemployment rate is a good indicator to spot a time of crisis.

So, I figured that there's a lot of columns here (56!). Some of them really don't matter to the things that I'm trying to figure out, but I'll leave them there in the dataset by now so that I can have more options to analyse in the future if I need to.

#### Playing a little bit
```{r}
uk_dataxl_tidy %>%
  subset(Year> 1930) %>%
  ggplot(aes(Year)) +
  geom_line(aes(y = `Unemployment rate`, colour = "Unemployment Rate")) 
```

```{r}
uk_dataxl_tidy %>%
  subset(Year> 1970 & Year < 1995) %>%
  ggplot(aes(Year)) +
  geom_line(aes(y = `Trade deficit`, colour = "Trade deficit"))
```

```{r}
uk_dataxl_tidy %>%
  subset(Year> 1970 & Year < 1995) %>%
  ggplot(aes(Year)) +
  geom_line(aes(y = `Unemployment rate`, colour = "Unemployment")) +
  scale_x_continuous(breaks = c(1970, 1975, 1980, 1985, 1990, 1995)) 
```